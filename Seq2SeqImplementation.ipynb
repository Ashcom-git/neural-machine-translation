{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence implementation**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nYHE_1ck2az"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
    "\n",
    "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
    " so do read the references completly and after that only please check the internet.\n",
    " The best things is to read the research papers and try to implement it on your own. \n",
    "\n",
    "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
    "\n",
    "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
    " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
    "with out learning much and didn't spend your time productively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyfZo8fmLOec"
   },
   "source": [
    "## Task -1: Simple Encoder and Decoder\n",
    "Implement simple Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvNSZXNkkOkO"
   },
   "source": [
    "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find **ita.txt** file in that ZIP, \n",
    "you can read that data using python and preprocess that data this way only: \n",
    "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
    "    \n",
    "3. You have to implement a simple Encoder and Decoder architecture  \n",
    "\n",
    "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "6.  a. Check the reference notebook <br>\n",
    "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv8f-1HxVMka",
    "outputId": "11f9011a-6d46-4ff5-8200-42a67b8c980a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CL6pN9utddX9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6F_IohGFSrB",
    "outputId": "59c5c3db-3bea-4f3a-edd7-34da80c0e1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/Attention mechanism/ita-eng.zip\n",
      "  inflating: ita.txt                 \n",
      "  inflating: _about.txt              \n"
     ]
    }
   ],
   "source": [
    "! unzip '/content/drive/MyDrive/Attention mechanism/ita-eng.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "fU80Ao-AGaob",
    "outputId": "37554a70-b9c1-497f-f190-3ecf40af92c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "      <th>meta_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Chi?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian                                          meta_data\n",
       "0     Hi.     Ciao!  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "1    Run!    Corri!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "2    Run!    Corra!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "3    Run!  Correte!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "4    Who?      Chi?  CC-BY 2.0 (France) Attribution: tatoeba.org #2..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/content/ita.txt',sep=\"\\t\",header=None, names=['english','italian','meta_data'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "ZjGlGiF6A99l",
    "outputId": "e6f47284-bec1-4f57-ad53-c80c8a92b124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "      <th>meta_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>corri</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>corra</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>correte</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who</td>\n",
       "      <td>chi</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  italian                                          meta_data\n",
       "0      hi     ciao  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
       "1     run    corri  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "2     run    corra  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "3     run  correte  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
       "4     who      chi  CC-BY 2.0 (France) Attribution: tatoeba.org #2..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert all the text into lower letters\n",
    "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
    "    # remove all the spacial characters: except space ' '\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_ita(text):\n",
    "    # convert all the text into lower letters\n",
    "    # remove the words betweent brakets ()\n",
    "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
    "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
    "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
    "    # you are free to do more proprocessing\n",
    "    # note that the model will learn better with better preprocessed data \n",
    "    \n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['italian'] = data['italian'].apply(preprocess_ita)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "2h-WfPzUTCAk",
    "outputId": "7d37c106-3811-4bef-a4cd-c44e8d230fd1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correte</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chi</td>\n",
       "      <td>&lt;start&gt; who</td>\n",
       "      <td>who &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   italian  english_inp english_out\n",
       "0     ciao   <start> hi    hi <end>\n",
       "1    corri  <start> run   run <end>\n",
       "2    corra  <start> run   run <end>\n",
       "3  correte  <start> run   run <end>\n",
       "4      chi  <start> who   who <end>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['italian_len'] = data['italian'].str.split().apply(len)\n",
    "data = data[data['italian_len'] < 20]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < 20]\n",
    "\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','italian_len','english_len','meta_data'], axis=1)\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yKpjhVYCNZqQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-es0ofqPj_B",
    "outputId": "8a40f3ed-d9a4-44d0-af52-9f232f136e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275852, 3) (68964, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "ow3eWEPn5wo8",
    "outputId": "8c9c9122-889f-4aa1-bc88-1942e85db96d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58423</th>\n",
       "      <td>come sta sua madre</td>\n",
       "      <td>&lt;start&gt; how is your mother &lt;end&gt;</td>\n",
       "      <td>how is your mother &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281771</th>\n",
       "      <td>sto cercando un anello di fidanzamento</td>\n",
       "      <td>&lt;start&gt; i am looking for an engagement ring</td>\n",
       "      <td>i am looking for an engagement ring &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47625</th>\n",
       "      <td>io devo andarmene da qui</td>\n",
       "      <td>&lt;start&gt; i must leave here</td>\n",
       "      <td>i must leave here &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13157</th>\n",
       "      <td>io ero geloso</td>\n",
       "      <td>&lt;start&gt; i was jealous</td>\n",
       "      <td>i was jealous &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225885</th>\n",
       "      <td>guardo la tv quasi ogni sera</td>\n",
       "      <td>&lt;start&gt; i watch tv almost every night</td>\n",
       "      <td>i watch tv almost every night &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       italian  ...                                english_out\n",
       "58423                       come sta sua madre  ...             how is your mother <end> <end>\n",
       "281771  sto cercando un anello di fidanzamento  ...  i am looking for an engagement ring <end>\n",
       "47625                 io devo andarmene da qui  ...                    i must leave here <end>\n",
       "13157                            io ero geloso  ...                        i was jealous <end>\n",
       "225885            guardo la tv quasi ogni sera  ...        i watch tv almost every night <end>\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "BD97Yoa9Q5iU",
    "outputId": "75c67643-086d-49ec-88b7-bc820014e05a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247572</th>\n",
       "      <td>sei sicuro che tom non sarà arrabbiato</td>\n",
       "      <td>&lt;start&gt; are you sure tom will not be angry</td>\n",
       "      <td>are you sure tom will not be angry &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237206</th>\n",
       "      <td>io penso sicuramente che sia fattibile</td>\n",
       "      <td>&lt;start&gt; i definitely think it is doable</td>\n",
       "      <td>i definitely think it is doable &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267105</th>\n",
       "      <td>tom dice di voler perdere peso</td>\n",
       "      <td>&lt;start&gt; tom says he wants to lose weight</td>\n",
       "      <td>tom says he wants to lose weight &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277264</th>\n",
       "      <td>cosha fatto con i libri</td>\n",
       "      <td>&lt;start&gt; what have you done with the books</td>\n",
       "      <td>what have you done with the books &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64297</th>\n",
       "      <td>loro non sono stupide</td>\n",
       "      <td>&lt;start&gt; they are not stupid</td>\n",
       "      <td>they are not stupid &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       italian  ...                               english_out\n",
       "247572  sei sicuro che tom non sarà arrabbiato  ...  are you sure tom will not be angry <end>\n",
       "237206  io penso sicuramente che sia fattibile  ...     i definitely think it is doable <end>\n",
       "267105          tom dice di voler perdere peso  ...    tom says he wants to lose weight <end>\n",
       "277264                 cosha fatto con i libri  ...   what have you done with the books <end>\n",
       "64297                    loro non sono stupide  ...                 they are not stupid <end>\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8RDrP4xKabR"
   },
   "source": [
    "## <font color='blue'>**Implement custom encoder decoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A45uc0JILMlV"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cex2XfCLOew"
   },
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "      super().__init__()\n",
    "      self.lstm_size = lstm_size\n",
    "      self.embedding_layer = Embedding(input_dim=inp_vocab_size,output_dim=embedding_size,input_length=input_length, mask_zero=True)  \n",
    "      self.lstm = LSTM(lstm_size,return_state=True,return_sequences=True)\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "      '''\n",
    "        This function takes a sequence input and the initial states of the encoder.\n",
    "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "        returns -- encoder_output, last time step's hidden and cell state\n",
    "      '''\n",
    "      self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(self.embedding_layer(input_sequence))\n",
    "      return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      self.lstm_state_h = tf.zeros([batch_size,self.lstm_size ])\n",
    "      self.lstm_state_c = tf.zeros([batch_size,self.lstm_size ])\n",
    "      return self.lstm_state_h, self.lstm_state_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtbOI3VwLOe0"
   },
   "source": [
    "<font color='orange'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ziSqOgmhLOe1",
    "outputId": "99dfb634-b456-42e6-a649-923242c6a4b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    #Intialzing encoder \n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    #Intializing encoder initial states\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    \n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1ES1-sJLOe4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "      super().__init__()\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Decoder LSTM layer    \n",
    "      self.embedding_layer = Embedding(input_dim=out_vocab_size,output_dim=embedding_size,input_length=input_length)  \n",
    "      self.lstm = LSTM(lstm_size,return_state=True,return_sequences=True)   \n",
    " \n",
    "\n",
    "\n",
    "    def call(self,input_sequence,initial_states):\n",
    "      '''\n",
    "        This function takes a sequence input and the initial states of the encoder.\n",
    "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "      \n",
    "        returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "      '''\n",
    "      decoder_output,decoder_final_state_h,decoder_final_state_c = self.lstm(self.embedding_layer(input_sequence),initial_state=initial_states)\n",
    "      return decoder_output,decoder_final_state_h,decoder_final_state_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq-I0SUbLOe8"
   },
   "source": [
    "<font color='orange'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0B0gokgKLOe8",
    "outputId": "7af5875b-1b30-42ec-a2fc-a3317427de73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder():\n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    states=[state_h,state_c]\n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
    "    output,_,_=decoder(target_sentences, states)\n",
    "    assert(output.shape==(batch_size,input_length,dec_units))\n",
    "    return True\n",
    "print(grader_decoder())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HhyQgu_7MpTQ"
   },
   "outputs": [],
   "source": [
    "tknizer_ita = Tokenizer()\n",
    "tknizer_ita.fit_on_texts(train['italian'].values)\n",
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFAjnZ4E_aoj",
    "outputId": "f2424f9a-87b6-4343-e91b-bba0e7ed2983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12858\n",
      "26238\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
    "print(vocab_size_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_oCpnReBvqhT"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['italian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_ita = tknizer_ita\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIUVPbUvvxdM",
    "outputId": "dffedf89-856c-4e82-d1ac-35111d34a282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 20) (1024, 20) (1024, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
    "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=1024)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=1024)\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXrIj4scLOe_"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(Model):\n",
    "    \n",
    "    def __init__(self,*params):\n",
    "      super().__init__()    \n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        # inp_vocab_size,embedding_size,lstm_size,input_length)\n",
    "      self.inp_vocab_size = params[0]\n",
    "      self.embedding_size = params[1]\n",
    "      self.lstm_size = params[2]\n",
    "      self.input_length_enc = params[3]\n",
    "      self.input_length_dec = params[4]\n",
    "      self.out_vocab_size = params[5]\n",
    "      self.encoder = Encoder(inp_vocab_size=self.inp_vocab_size+1,embedding_size=self.embedding_size[0],lstm_size=self.lstm_size,input_length=self.input_length_enc)\n",
    "      self.decoder = Decoder(out_vocab_size=self.out_vocab_size+1,embedding_size=self.embedding_size[1],lstm_size=self.lstm_size,input_length=self.input_length_dec)\n",
    "      self.dense = Dense(self.out_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self,data):\n",
    "      '''\n",
    "      A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "      B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "      C. Pass the decoder_outputs into Dense layer \n",
    "      \n",
    "      Return decoder_outputs\n",
    "      '''\n",
    "      self.input_data = data[0]\n",
    "      self.output_data = data[1]\n",
    "      initial_state = self.encoder.initialize_states(1024)\n",
    "      encoder_output,encoder_final_state_h,encoder_final_state_c = self.encoder(self.input_data,initial_state) \n",
    "      decoder_output,_,_ = self.decoder(self.output_data,[encoder_final_state_h,encoder_final_state_c])\n",
    "      current_output = self.dense(decoder_output)\n",
    "\n",
    "      return current_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oV9t9on9Dm6r",
    "outputId": "e74bdc81-104d-49f7-ba40-db12b75cdd60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "269/269 [==============================] - 57s 196ms/step - loss: 3.6955 - val_loss: 1.7061\n",
      "Epoch 2/12\n",
      "269/269 [==============================] - 51s 188ms/step - loss: 1.6564 - val_loss: 1.4745\n",
      "Epoch 3/12\n",
      "269/269 [==============================] - 51s 188ms/step - loss: 1.4243 - val_loss: 1.2869\n",
      "Epoch 4/12\n",
      "269/269 [==============================] - 51s 190ms/step - loss: 1.2553 - val_loss: 1.1538\n",
      "Epoch 5/12\n",
      "269/269 [==============================] - 52s 192ms/step - loss: 1.1288 - val_loss: 1.0460\n",
      "Epoch 6/12\n",
      "269/269 [==============================] - 51s 191ms/step - loss: 1.0259 - val_loss: 0.9489\n",
      "Epoch 7/12\n",
      "269/269 [==============================] - 51s 190ms/step - loss: 0.9283 - val_loss: 0.8624\n",
      "Epoch 8/12\n",
      "269/269 [==============================] - 51s 189ms/step - loss: 0.8478 - val_loss: 0.7885\n",
      "Epoch 9/12\n",
      "269/269 [==============================] - 51s 189ms/step - loss: 0.7757 - val_loss: 0.7214\n",
      "Epoch 10/12\n",
      "269/269 [==============================] - 51s 190ms/step - loss: 0.7115 - val_loss: 0.6586\n",
      "Epoch 11/12\n",
      "269/269 [==============================] - 51s 189ms/step - loss: 0.6500 - val_loss: 0.6022\n",
      "Epoch 12/12\n",
      "269/269 [==============================] - 51s 189ms/step - loss: 0.5924 - val_loss: 0.5498\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  1626318   \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  1651468   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  3304506   \n",
      "=================================================================\n",
      "Total params: 6,582,292\n",
      "Trainable params: 6,582,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "\n",
    "model = Encoder_decoder(len(tknizer_ita.word_index),(50,100),256,20,20,len(tknizer_eng.word_index))\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=12, validation_data=train_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkARSlZgLOfE"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "          predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
    "          pass the predicted_out to the dense layer\n",
    "          update the states=[state_h,state_c]\n",
    "          And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
    "          Update the input_to_decoder with current predictions\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "\n",
    "  token_sequence = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "  pad_seq = pad_sequences(token_sequence, padding='post', maxlen=20)\n",
    "\n",
    "  initial_state = model.layers[0].initialize_states(1024)\n",
    " \n",
    "  encoder_output,hidden_state_enc,cell_state_enc = model.layers[0](pad_seq,initial_state)\n",
    "  pred_sent = []\n",
    "  state_values = [hidden_state_enc,cell_state_enc]\n",
    "  cur_vec = tf.expand_dims([tknizer_eng.word_index['<start>']],0)\n",
    "\n",
    "  for i in range(20):\n",
    "\n",
    "    cur_emb = model.layers[1].embedding_layer(cur_vec)\n",
    "    decoder_output,state_h,state_c = model.layers[1].lstm(cur_emb,state_values)\n",
    "    predicted_out = model.layers[2](decoder_output)\n",
    "    state_values = [state_h,state_c]\n",
    "    cur_vec = np.reshape(np.argmax(predicted_out),(1,1))\n",
    "\n",
    "    if np.squeeze(cur_vec) != tknizer_eng.word_index['<end>']:\n",
    "      pred_sent.append(tknizer_eng.index_word[int(np.squeeze(cur_vec))]) \n",
    "    else:  \n",
    "      break\n",
    "     \n",
    "  return ' '.join(pred_sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpQo4Nf7k8eI",
    "outputId": "b06817ae-012a-43a3-dd1f-d71394274914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.8081453347183427\n"
     ]
    }
   ],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "\n",
    "rand_val = np.random.randint(0,len(validation),size=(1000))\n",
    "iter_val = validation.iloc[rand_val,:].apply(lambda x: bleu.sentence_bleu(x['english_out'][:-6],predict(x['italian'])),axis=1)\n",
    "print(\"BLEU score:\",np.sum(iter_val.values)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWFDxZXLOfJ"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZhX3K9GLOfJ"
   },
   "source": [
    "## Task -2: Including Attention mechanisum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3d7GeBMGbsJ"
   },
   "source": [
    "1. Use the preprocessed data from Task-1\n",
    "\n",
    "2. You have to implement an Encoder and Decoder architecture with  \n",
    "attention as discussed in the reference notebook.\n",
    "\n",
    "    * Encoder   - with 1 layer LSTM <br>\n",
    "    * Decoder   - with 1 layer LSTM<br>\n",
    "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
    "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
    " As a part of this assignment **you need to create 3 models for each scoring function**\n",
    "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
    "\n",
    "    * In model 1 you need to implemnt \"dot\" score function\n",
    "    * In model 2 you need to implemnt \"general\" score function\n",
    "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
    "    \n",
    " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
    "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
    "\n",
    "5. Using attention weights, you can plot the attention plots, \n",
    "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
    "\n",
    "6. The attention layer has to be written by yourself only. \n",
    "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
    "\n",
    "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
    "\n",
    "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
    " Check the reference notebook for better understanding.\n",
    "\n",
    "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "11. Resources:\n",
    "    a. Check the reference notebook\n",
    "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
    "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
    "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4KIsGxLOfK"
   },
   "source": [
    "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMm3ADQDLOfK"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Lx_5NA24KzRp"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "\n",
    "        self.embedding = Embedding(input_dim=inp_vocab_size,output_dim=embedding_size,input_length=input_length)  \n",
    "        self.lstm = LSTM(lstm_size,return_state=True,return_sequences=True)\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "      input_embedd = self.embedding(input_sequence)\n",
    "      self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "      return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      \n",
    "      self.lstm_state_h = tf.zeros([batch_size,self.lstm_size ])\n",
    "      self.lstm_state_c = tf.zeros([batch_size,self.lstm_size ])\n",
    "      return [self.lstm_state_h,self.lstm_state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ub9aN-hK244"
   },
   "source": [
    "<font color='cyan'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRoe65b9LB0D",
    "outputId": "de0f574d-fb1d-4f6f-9c40-6966e175982d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    \n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units in encoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    \n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXn278lhLYRM"
   },
   "source": [
    "<font color='blue'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ab5SNdPZLlur"
   },
   "outputs": [],
   "source": [
    "#Reference: https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
    "\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,scoring_function, att_units):\n",
    "    super().__init__()\n",
    "    self.scoring_function = scoring_function\n",
    "    self.att_units = att_units\n",
    "\n",
    "\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "\n",
    "    if self.scoring_function=='dot':\n",
    "      # Intialize variables needed for Dot score function here\n",
    "      self.score = 0\n",
    "      \n",
    "    if scoring_function == 'general':\n",
    "      # Intialize variables needed for General score function here\n",
    "      self.W1 = tf.keras.layers.Dense(self.att_units)\n",
    "      self.score = 0\n",
    "\n",
    "    elif scoring_function == 'concat':\n",
    "      # Intialize variables needed for Concat score function here\n",
    "      self.W1 = tf.keras.layers.Dense(self.att_units)\n",
    "      self.W2 = tf.keras.layers.Dense(self.att_units)\n",
    "      self.V = tf.keras.layers.Dense(1)\n",
    "      self.score = 0\n",
    "  \n",
    "  \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    \n",
    "    if self.scoring_function == 'dot':\n",
    "        # Implement Dot score function here\n",
    "        query_with_time_axis = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        self.score = tf.matmul(encoder_output, tf.transpose(query_with_time_axis, perm=[0,2,1]))\n",
    "       \n",
    "    elif self.scoring_function == 'general':\n",
    "        # Implement General score function here\n",
    "        query_with_time_axis = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        self.score = tf.matmul(self.W1(encoder_output),tf.transpose(query_with_time_axis, perm=[0,2,1]))\n",
    "\n",
    "    elif self.scoring_function == 'concat':\n",
    "        # Implement General score function here\n",
    "        query_with_time_axis = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        self.score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(encoder_output)))\n",
    "        \n",
    "\n",
    "    attention_weights = tf.nn.softmax(self.score, axis=1)\n",
    "    context_vector = attention_weights * encoder_output\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)   \n",
    "    \n",
    "    return context_vector, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExQDlxI9LuqK"
   },
   "source": [
    "<font color='cyan'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51x50h_TLrl9",
    "outputId": "4530cfa1-0256-488d-ae49-7a640d06c7fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_attention(scoring_fun):\n",
    "    \n",
    "    ''' \n",
    "        att_units: Used in matrix multiplications for scoring functions,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    \n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    att_units=32\n",
    "    \n",
    "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
    "    attention=Attention(scoring_fun,att_units)\n",
    "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
    "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
    "    return True\n",
    "print(grader_check_attention('dot'))\n",
    "print(grader_check_attention('general'))\n",
    "print(grader_check_attention('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-FNEbfL2DN"
   },
   "source": [
    "<font color='blue'>**OneStepDecoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Kc8m7lmOL097"
   },
   "outputs": [],
   "source": [
    "#Reference: https://datascience.stackexchange.com/questions/64433/symbolicexception-inputs-to-eager-execution-function-cannot-be-keras-symbolic-t\n",
    "\n",
    "class One_Step_Decoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = tar_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units = dec_units\n",
    "      self.score_fun = score_fun\n",
    "      self.att_units = att_units\n",
    "      self.attention = Attention(self.score_fun,self.att_units)\n",
    "      self.embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,mask_zero=True)\n",
    "      self.lstm = LSTM(units=self.dec_units,return_sequences=True,return_state=True)\n",
    "      self.dense = Dense(self.tar_vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "    output_embedding = self.embedding(input_to_decoder)\n",
    "    context_vector,attention_weights = self.attention(state_h,encoder_output)\n",
    "    conc_vec = tf.concat([tf.expand_dims(context_vector,1),output_embedding], axis=-1)\n",
    "    lstm_out, lstm_h, lstm_c = self.lstm(conc_vec)\n",
    "    decoder_output = self.dense(lstm_out)\n",
    "\n",
    "    return tf.squeeze(decoder_output), lstm_h, lstm_c, attention_weights, context_vector \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_I8I4EIMAXq"
   },
   "source": [
    "<font color='cyan'>**Grader function - 3**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLEXhChnMC1k",
    "outputId": "cb2e06fa-81ff-4db8-a125-2816aba97f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_onestepdecoder(score_fun):\n",
    "    \n",
    "    '''\n",
    "        tar_vocab_size: Unique words of the target language,\n",
    "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
    "        input_length: Length of the target sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tar_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    onestepdecoder=One_Step_Decoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
    "    assert(output.shape==(batch_size,tar_vocab_size))\n",
    "    assert(state_h.shape==(batch_size,dec_units))\n",
    "    assert(state_c.shape==(batch_size,dec_units))\n",
    "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
    "    assert(context_vector.shape==(batch_size,dec_units))\n",
    "    return True\n",
    "    \n",
    "print(grader_onestepdecoder('dot'))\n",
    "print(grader_onestepdecoder('general'))\n",
    "print(grader_onestepdecoder('concat'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "<font color='blue'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NV-x31rj6Hc4"
   },
   "outputs": [],
   "source": [
    "#Reference: https://github.com/Douboo/tf_env_debug/blob/master/custom_layers_and_model_subclassing_API.ipynb\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units = dec_units\n",
    "      self.score_fun = score_fun\n",
    "      self.att_units = att_units\n",
    "      self.onestepdecoder = One_Step_Decoder(self.tar_vocab_size, self.embedding_dim, self.input_length, self.dec_units , self.score_fun , self.att_units)\n",
    "\n",
    "\n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        array = tf.TensorArray(tf.float32, size=20)\n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "        for i in range(20):\n",
    "          output,state_h,state_c,attention_weights,context_vector=self.onestepdecoder(input_to_decoder[:,i:i+1],encoder_output,decoder_hidden_state,decoder_cell_state)  \n",
    "          array = array.write(i,output)\n",
    "        array = tf.transpose(array.stack(), [1, 0, 2])\n",
    "        \n",
    "        return array \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOZIU9Yq3BJB"
   },
   "source": [
    "The value 20 has been hardcoded specifically during training of the model because input_to_decoder.shape[1] was returning None. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxrL-P8bMJH6"
   },
   "source": [
    "<font color='cyan'>**Grader function - 4**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtbx6onFMJXb",
    "outputId": "569236c7-434e-46d3-ad1a-13a853165467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder(score_fun):\n",
    "    \n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
    "        input_length: Length of the target sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=11\n",
    "    dec_units=16 \n",
    "    att_units=16\n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    \n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
    "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
    "    return True\n",
    "print(grader_decoder('dot'))\n",
    "print(grader_decoder('general'))\n",
    "print(grader_decoder('concat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "<font color='blue'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FfqBIe20MT3D"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,*params):\n",
    "    super().__init__()\n",
    "    #Intialize objects from encoder decoder\n",
    "    self.inp_vocab_size = params[0]\n",
    "    self.embedding_size = params[1]\n",
    "    self.lstm_size = params[2]\n",
    "    self.input_length_enc = params[3]\n",
    "    self.input_length_dec = params[4]\n",
    "    self.out_vocab_size = params[5]\n",
    "    self.score_fun = params[6]\n",
    "    self.att_units = params[7]\n",
    "    self.encoder = Encoder(inp_vocab_size=self.inp_vocab_size+1,embedding_size=self.embedding_size[0],lstm_size=self.lstm_size,input_length=self.input_length_enc)\n",
    "    self.decoder = Decoder(out_vocab_size=self.out_vocab_size+1,embedding_dim=self.embedding_size[1],dec_units=self.lstm_size,input_length=self.input_length_dec,score_fun=self.score_fun,att_units=self.att_units)\n",
    "\n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    self.input_data = data[0]\n",
    "    self.output_data = data[1]\n",
    "    initial_state = self.encoder.initialize_states(1024)\n",
    "    encoder_output,encoder_final_state_h,encoder_final_state_c = self.encoder(self.input_data,initial_state) \n",
    "    decoder_output = self.decoder(self.output_data,encoder_output,encoder_final_state_h,encoder_final_state_c)\n",
    "    \n",
    "    return decoder_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QY_3izrXMs8y"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def custom_lossfunction(targets,logits):\n",
    "\n",
    "  # Custom loss function that will not consider the loss for padded zeros.\n",
    "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
    "  \n",
    "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "  loss_ = loss_object(targets,logits)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QlbWAqNNlqe"
   },
   "source": [
    "<font color='blue'>**Training**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtZUQF2NuZE"
   },
   "source": [
    "Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgyWwZWeMxGQ",
    "outputId": "fb6159e8-9abb-4348-d2d6-ad1dcd100455"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "269/269 [==============================] - 111s 312ms/step - loss: 2.1253 - val_loss: 1.6707\n",
      "Epoch 2/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 1.6252 - val_loss: 1.4590\n",
      "Epoch 3/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 1.4379 - val_loss: 1.3812\n",
      "Epoch 4/20\n",
      "269/269 [==============================] - 77s 285ms/step - loss: 1.3723 - val_loss: 1.3473\n",
      "Epoch 5/20\n",
      "269/269 [==============================] - 77s 287ms/step - loss: 1.3389 - val_loss: 1.3269\n",
      "Epoch 6/20\n",
      "269/269 [==============================] - 77s 287ms/step - loss: 1.3166 - val_loss: 1.3133\n",
      "Epoch 7/20\n",
      "269/269 [==============================] - 78s 288ms/step - loss: 1.3018 - val_loss: 1.3031\n",
      "Epoch 8/20\n",
      "269/269 [==============================] - 77s 285ms/step - loss: 1.2913 - val_loss: 1.2959\n",
      "Epoch 9/20\n",
      "269/269 [==============================] - 77s 285ms/step - loss: 1.2799 - val_loss: 1.2901\n",
      "Epoch 10/20\n",
      "269/269 [==============================] - 77s 284ms/step - loss: 1.2742 - val_loss: 1.2850\n",
      "Epoch 11/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 1.2567 - val_loss: 1.2163\n",
      "Epoch 12/20\n",
      "269/269 [==============================] - 76s 284ms/step - loss: 1.1784 - val_loss: 1.1293\n",
      "Epoch 13/20\n",
      "269/269 [==============================] - 77s 287ms/step - loss: 1.0796 - val_loss: 1.0272\n",
      "Epoch 14/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.9783 - val_loss: 0.9500\n",
      "Epoch 15/20\n",
      "269/269 [==============================] - 77s 288ms/step - loss: 0.8973 - val_loss: 0.8868\n",
      "Epoch 16/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.8244 - val_loss: 0.8318\n",
      "Epoch 17/20\n",
      "269/269 [==============================] - 78s 289ms/step - loss: 0.7633 - val_loss: 0.7812\n",
      "Epoch 18/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.7046 - val_loss: 0.7357\n",
      "Epoch 19/20\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.6526 - val_loss: 0.6963\n",
      "Epoch 20/20\n",
      "269/269 [==============================] - 77s 285ms/step - loss: 0.6039 - val_loss: 0.6628\n",
      "Model: \"encoder_decoder_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_5 (Encoder)          multiple                  3408000   \n",
      "_________________________________________________________________\n",
      "decoder_3 (Decoder)          multiple                  2547579   \n",
      "=================================================================\n",
      "Total params: 5,955,579\n",
      "Trainable params: 5,955,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Implement teacher forcing while training your model. You can do it two ways.\n",
    "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
    "# if decoder input is \n",
    "# <start> Hi how are you\n",
    "# decoder output should be\n",
    "# Hi How are you <end>\n",
    "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
    "\n",
    "# or\n",
    " \n",
    "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
    "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
    "\n",
    "model2_dot = encoder_decoder(len(tknizer_ita.word_index),(128,128),64,20,20,len(tknizer_eng.word_index),'dot',64)\n",
    "optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "model2_dot.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "model2_dot.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model2_dot.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gp2tdCzjrxZH",
    "outputId": "a35c6651-6e22-45ce-e506-833edf1ad21a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "269/269 [==============================] - 77s 287ms/step - loss: 0.5549 - val_loss: 0.6290\n",
      "Epoch 2/5\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.5194 - val_loss: 0.6059\n",
      "Epoch 3/5\n",
      "269/269 [==============================] - 77s 285ms/step - loss: 0.4885 - val_loss: 0.5855\n",
      "Epoch 4/5\n",
      "269/269 [==============================] - 77s 287ms/step - loss: 0.4617 - val_loss: 0.5685\n",
      "Epoch 5/5\n",
      "269/269 [==============================] - 76s 284ms/step - loss: 0.4383 - val_loss: 0.5543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e27d28d10>"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_dot.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=5, validation_data=test_dataloader, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Af4_Sg9btdDH",
    "outputId": "89b6c813-e98e-4665-e814-d24f38baf00f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.4175 - val_loss: 0.5434\n",
      "Epoch 2/5\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.3999 - val_loss: 0.5318\n",
      "Epoch 3/5\n",
      "269/269 [==============================] - 77s 288ms/step - loss: 0.3836 - val_loss: 0.5238\n",
      "Epoch 4/5\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.3694 - val_loss: 0.5175\n",
      "Epoch 5/5\n",
      "269/269 [==============================] - 77s 286ms/step - loss: 0.3566 - val_loss: 0.5103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f904cb3ff50>"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_dot.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=5, validation_data=test_dataloader, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DpC9zlzMcXp"
   },
   "source": [
    "## <font color='blue'>**Inference**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5NhESYyMW_t"
   },
   "source": [
    "<font color='blue'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pkEY7SsBMtrC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1IhdBrgQYJr"
   },
   "source": [
    "<font color='blue'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MP3kLZoPMvSu"
   },
   "outputs": [],
   "source": [
    "def predict_dot(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  token_sequence = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "  pad_seq = pad_sequences(token_sequence, padding='post', maxlen=20)\n",
    "\n",
    "  initial_state = model2_dot.layers[0].initialize_states(1024)\n",
    "  encoder_output,hidden_state_enc,cell_state_enc = model2_dot.layers[0](pad_seq,initial_state)\n",
    "  state_values = [hidden_state_enc,cell_state_enc]\n",
    "  cur_vec = tf.expand_dims([tknizer_eng.word_index['<start>']],0)\n",
    "\n",
    "  global attention_plot\n",
    "  attention_plot = np.zeros((20, 20))\n",
    "  result = ''\n",
    "  predictions = []\n",
    "\n",
    "  for f in range(20):\n",
    "    output,state_h,state_c,attention_weights,context_vector = model2_dot.layers[1].onestepdecoder(cur_vec, encoder_output, state_values[0],state_values[1])\n",
    "    state_values = [state_h,state_c]\n",
    "\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[f] = attention_weights.numpy()\n",
    "    \n",
    "    predicted_id = tf.argmax(output).numpy()\n",
    "\n",
    "    if tknizer_eng.index_word[predicted_id] == '<end>':\n",
    "      break\n",
    "    \n",
    "    cur_vec = tf.expand_dims([predicted_id], 0)\n",
    "    result += tknizer_eng.index_word[predicted_id] + ' '\n",
    "\n",
    "  return result.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "UHQQV4sgwVUg",
    "outputId": "7489a856-c193-4d7f-fc27-3e88513fe2ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = validation.iloc[0,:]['italian']\n",
    "result = predict_dot(input_sentence)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(input_sentence.split(' '))]\n",
    "plot_attention(attention_plot, input_sentence.split(' '), result.strip().split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmxIVOOQPWMu"
   },
   "source": [
    "<font color='blue'>**Calculate BLEU score**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvZe0Md4vnM9",
    "outputId": "c38ae988-5b7c-425a-d9c8-fa775e408ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.7563061593669899\n"
     ]
    }
   ],
   "source": [
    "#Create an object of your custom model.\n",
    "#Compile and train your model on dot scoring function.\n",
    "# Visualize few sentences randomly in Test data\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "\n",
    "rand_val = np.random.randint(0,len(validation),size=(1000))\n",
    "iter_val = validation.iloc[rand_val,:].apply(lambda x: bleu.sentence_bleu(x['english_out'][:-6],predict_dot(x['italian'])),axis=1)\n",
    "print(\"BLEU score:\",np.sum(iter_val.values)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWg2ferDQvT3"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Rh9_w79M5JO",
    "outputId": "54e85261-8038-4e61-d6c0-24efe53c734e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "269/269 [==============================] - 111s 314ms/step - loss: 2.1263 - val_loss: 1.6356\n",
      "Epoch 2/30\n",
      "269/269 [==============================] - 79s 292ms/step - loss: 1.5772 - val_loss: 1.4396\n",
      "Epoch 3/30\n",
      "269/269 [==============================] - 79s 294ms/step - loss: 1.4232 - val_loss: 1.3719\n",
      "Epoch 4/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 1.3606 - val_loss: 1.3406\n",
      "Epoch 5/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 1.3307 - val_loss: 1.3221\n",
      "Epoch 6/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 1.3117 - val_loss: 1.3099\n",
      "Epoch 7/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 1.2982 - val_loss: 1.3006\n",
      "Epoch 8/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 1.2872 - val_loss: 1.2936\n",
      "Epoch 9/30\n",
      "269/269 [==============================] - 78s 292ms/step - loss: 1.2790 - val_loss: 1.2731\n",
      "Epoch 10/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 1.2420 - val_loss: 1.1949\n",
      "Epoch 11/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 1.1509 - val_loss: 1.0921\n",
      "Epoch 12/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 1.0456 - val_loss: 1.0010\n",
      "Epoch 13/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.9496 - val_loss: 0.9214\n",
      "Epoch 14/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.8675 - val_loss: 0.8561\n",
      "Epoch 15/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.7945 - val_loss: 0.7995\n",
      "Epoch 16/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.7321 - val_loss: 0.7511\n",
      "Epoch 17/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.6714 - val_loss: 0.7094\n",
      "Epoch 18/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.6225 - val_loss: 0.6753\n",
      "Epoch 19/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.5785 - val_loss: 0.6435\n",
      "Epoch 20/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.5408 - val_loss: 0.6189\n",
      "Epoch 21/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.5062 - val_loss: 0.5968\n",
      "Epoch 22/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.4771 - val_loss: 0.5798\n",
      "Epoch 23/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.4504 - val_loss: 0.5648\n",
      "Epoch 24/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.4307 - val_loss: 0.5523\n",
      "Epoch 25/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.4106 - val_loss: 0.5423\n",
      "Epoch 26/30\n",
      "269/269 [==============================] - 78s 289ms/step - loss: 0.3934 - val_loss: 0.5331\n",
      "Epoch 27/30\n",
      "269/269 [==============================] - 78s 291ms/step - loss: 0.3772 - val_loss: 0.5255\n",
      "Epoch 28/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.3627 - val_loss: 0.5197\n",
      "Epoch 29/30\n",
      "269/269 [==============================] - 78s 290ms/step - loss: 0.3496 - val_loss: 0.5141\n",
      "Epoch 30/30\n",
      "269/269 [==============================] - 78s 289ms/step - loss: 0.3397 - val_loss: 0.5102\n",
      "Model: \"encoder_decoder_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  3408000   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  2551739   \n",
      "=================================================================\n",
      "Total params: 5,959,739\n",
      "Trainable params: 5,959,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile and train your model on general scoring function.\n",
    "# Visualize few sentences randomly in Test data\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "\n",
    "\n",
    "model2_general = encoder_decoder(len(tknizer_ita.word_index),(128,128),64,20,20,len(tknizer_eng.word_index),'general',64)\n",
    "optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "model2_general.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "model2_general.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model2_general.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y0DdhBzl9Oip"
   },
   "outputs": [],
   "source": [
    "def predict_general(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  token_sequence = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "  pad_seq = pad_sequences(token_sequence, padding='post', maxlen=20)\n",
    "\n",
    "  initial_state = model2_general.layers[0].initialize_states(1024)\n",
    "  encoder_output,hidden_state_enc,cell_state_enc = model2_general.layers[0](pad_seq,initial_state)\n",
    "  state_values = [hidden_state_enc,cell_state_enc]\n",
    "  cur_vec = tf.expand_dims([tknizer_eng.word_index['<start>']],0)\n",
    "\n",
    "  global attention_plot\n",
    "  attention_plot = np.zeros((20, 20))\n",
    "  result = ''\n",
    "  predictions = []\n",
    "\n",
    "  for f in range(20):\n",
    "    output,state_h,state_c,attention_weights,context_vector = model2_general.layers[1].onestepdecoder(cur_vec, encoder_output, state_values[0],state_values[1])\n",
    "    state_values = [state_h,state_c]\n",
    "\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[f] = attention_weights.numpy()\n",
    "    \n",
    "    predicted_id = tf.argmax(output).numpy()\n",
    "\n",
    "    if tknizer_eng.index_word[predicted_id] == '<end>':\n",
    "      break\n",
    "    \n",
    "    cur_vec = tf.expand_dims([predicted_id], 0)\n",
    "    result += tknizer_eng.index_word[predicted_id] + ' '\n",
    "\n",
    "  return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "t-tHNzrAGawQ",
    "outputId": "2e49f749-4610-4be5-b40a-bd9ebac4bbbb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = validation.iloc[1,:]['italian']\n",
    "result = predict_general(input_sentence)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(input_sentence.split(' '))]\n",
    "plot_attention(attention_plot, input_sentence.split(' '), result.strip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rT5BbyhDGyjt",
    "outputId": "91589877-b449-48c7-88e1-f90aa01beb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.7593959731689988\n"
     ]
    }
   ],
   "source": [
    "rand_val = np.random.randint(0,len(validation),size=(1000))\n",
    "iter_val = validation.iloc[rand_val,:].apply(lambda x: bleu.sentence_bleu(x['english_out'][:-6],predict_general(x['italian'])),axis=1)\n",
    "print(\"BLEU score:\",np.sum(iter_val.values)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB1jRUqZQ9AM"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kN9ZWViQNMB",
    "outputId": "b5d4f4e2-56af-46bc-81cf-24ea85ae64fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "269/269 [==============================] - 115s 327ms/step - loss: 2.1242 - val_loss: 1.6146\n",
      "Epoch 2/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 1.5052 - val_loss: 1.2322\n",
      "Epoch 3/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 1.1659 - val_loss: 0.9944\n",
      "Epoch 4/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.9353 - val_loss: 0.8293\n",
      "Epoch 5/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.7679 - val_loss: 0.7082\n",
      "Epoch 6/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 0.6390 - val_loss: 0.6192\n",
      "Epoch 7/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.5389 - val_loss: 0.5579\n",
      "Epoch 8/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.4666 - val_loss: 0.5144\n",
      "Epoch 9/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 0.4122 - val_loss: 0.4832\n",
      "Epoch 10/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.3695 - val_loss: 0.4605\n",
      "Epoch 11/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 0.3383 - val_loss: 0.4418\n",
      "Epoch 12/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.3100 - val_loss: 0.4300\n",
      "Epoch 13/30\n",
      "269/269 [==============================] - 80s 299ms/step - loss: 0.2911 - val_loss: 0.4208\n",
      "Epoch 14/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.2739 - val_loss: 0.4138\n",
      "Epoch 15/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.2569 - val_loss: 0.4082\n",
      "Epoch 16/30\n",
      "269/269 [==============================] - 80s 299ms/step - loss: 0.2455 - val_loss: 0.4036\n",
      "Epoch 17/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.2342 - val_loss: 0.4019\n",
      "Epoch 18/30\n",
      "269/269 [==============================] - 81s 303ms/step - loss: 0.2242 - val_loss: 0.3988\n",
      "Epoch 19/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.2174 - val_loss: 0.3977\n",
      "Epoch 20/30\n",
      "269/269 [==============================] - 80s 299ms/step - loss: 0.2091 - val_loss: 0.3959\n",
      "Epoch 21/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.2023 - val_loss: 0.3954\n",
      "Epoch 22/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.1963 - val_loss: 0.3957\n",
      "Epoch 23/30\n",
      "269/269 [==============================] - 81s 299ms/step - loss: 0.1898 - val_loss: 0.3952\n",
      "Epoch 24/30\n",
      "269/269 [==============================] - 81s 300ms/step - loss: 0.1875 - val_loss: 0.3978\n",
      "Epoch 25/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 0.1817 - val_loss: 0.3971\n",
      "Epoch 26/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.1775 - val_loss: 0.3972\n",
      "Epoch 27/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.1745 - val_loss: 0.3985\n",
      "Epoch 28/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 0.1712 - val_loss: 0.3995\n",
      "Epoch 29/30\n",
      "269/269 [==============================] - 80s 297ms/step - loss: 0.1685 - val_loss: 0.4013\n",
      "Epoch 30/30\n",
      "269/269 [==============================] - 80s 298ms/step - loss: 0.1655 - val_loss: 0.4023\n",
      "Model: \"encoder_decoder_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  3408000   \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  2555964   \n",
      "=================================================================\n",
      "Total params: 5,963,964\n",
      "Trainable params: 5,963,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile and train your model on concat scoring function.\n",
    "# Visualize few sentences randomly in Test data\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "\n",
    "model2_concat = encoder_decoder(len(tknizer_ita.word_index),(128,128),64,20,20,len(tknizer_eng.word_index),'concat',64)\n",
    "optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "model2_concat.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "model2_concat.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model2_concat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cP7KgRcCQ02b"
   },
   "outputs": [],
   "source": [
    "def predict_concat(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  token_sequence = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "  pad_seq = pad_sequences(token_sequence, padding='post', maxlen=20)\n",
    "\n",
    "  initial_state = model2_concat.layers[0].initialize_states(1024)\n",
    "  encoder_output,hidden_state_enc,cell_state_enc = model2_concat.layers[0](pad_seq,initial_state)\n",
    "  state_values = [hidden_state_enc,cell_state_enc]\n",
    "  cur_vec = tf.expand_dims([tknizer_eng.word_index['<start>']],0)\n",
    "\n",
    "  global attention_plot\n",
    "  attention_plot = np.zeros((20, 20))\n",
    "  result = ''\n",
    "  predictions = []\n",
    "\n",
    "  for f in range(20):\n",
    "    output,state_h,state_c,attention_weights,context_vector = model2_concat.layers[1].onestepdecoder(cur_vec, encoder_output, state_values[0],state_values[1])\n",
    "    state_values = [state_h,state_c]\n",
    "\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[f] = attention_weights.numpy()\n",
    "    \n",
    "    predicted_id = tf.argmax(output).numpy()\n",
    "    # predictions.append(predicted_id)\n",
    "\n",
    "    if tknizer_eng.index_word[predicted_id] == '<end>':\n",
    "      break\n",
    "    \n",
    "    cur_vec = tf.expand_dims([predicted_id], 0)\n",
    "    result += tknizer_eng.index_word[predicted_id] + ' '\n",
    "\n",
    "  return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "QvCnfsrmRGeS",
    "outputId": "85eb0871-52c2-4543-97db-790eceb24671"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sentence = validation.iloc[2,:]['italian']\n",
    "result = predict_concat(input_sentence)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(input_sentence.split(' '))]\n",
    "plot_attention(attention_plot, input_sentence.split(' '), result.strip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoC2ChwYRR2k",
    "outputId": "71c1875f-0dbd-478a-d355-03ff057b8ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.8086566488463641\n"
     ]
    }
   ],
   "source": [
    "rand_val = np.random.randint(0,len(validation),size=(1000))\n",
    "iter_val = validation.iloc[rand_val,:].apply(lambda x: bleu.sentence_bleu(x['english_out'][:-6],predict_concat(x['italian'])),axis=1)\n",
    "print(\"BLEU score:\",np.sum(iter_val.values)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5Xj_MG6R71N"
   },
   "source": [
    "#Write your observations on each of the scoring function - \n",
    "\n",
    "We created 3 different models, where each was implemented with one of the three attention score functions. All of them were trained for 30 epochs each. The models trainined with the concat and general score functions had a similar BLUE score of approximately 0.75. The model trainined using the concat function had a significantly greated BLEU score of approximately 0.80."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy_of_Seq2SeqImplementation__Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
